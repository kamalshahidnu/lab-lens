FROM python:3.12-slim

WORKDIR /app

# Install system dependencies
RUN apt-get update && apt-get install -y \
    build-essential \
    curl \
    git \
    && rm -rf /var/lib/apt/lists/*

# Copy requirements
COPY requirements.txt .

# Install Python dependencies
RUN pip install --no-cache-dir --upgrade pip && \
    pip install --no-cache-dir -r requirements.txt

# Install additional dependencies for PDF processing
RUN pip install --no-cache-dir pdfplumber

# Copy application code
COPY . .

# Create necessary directories with proper permissions
RUN mkdir -p models/vector_db logs /root/.cache/huggingface /root/.cache/sentence_transformers && \
    chmod -R 777 models logs /root/.cache/huggingface /root/.cache/sentence_transformers

# Optionally pre-download embedding models to avoid cold start issues.
# In CI we typically set SKIP_MODEL_DOWNLOAD=true to keep builds fast.
ARG SKIP_MODEL_DOWNLOAD=false
RUN if [ "$SKIP_MODEL_DOWNLOAD" = "true" ]; then \
      echo "⏭️  Skipping embedding model download (SKIP_MODEL_DOWNLOAD=true)"; \
    else \
      python3 infrastructure/docker/download_models.py || (echo "❌ Failed to download embedding models" && exit 1); \
    fi

# Set environment variables
ENV PYTHONPATH=/app
ENV STREAMLIT_SERVER_HEADLESS=true
ENV STREAMLIT_BROWSER_GATHER_USAGE_STATS=false
ENV HF_HOME=/root/.cache/huggingface
ENV TRANSFORMERS_CACHE=/root/.cache/huggingface
ENV SENTENCE_TRANSFORMERS_HOME=/root/.cache/huggingface
ENV HF_DATASETS_CACHE=/root/.cache/huggingface
ENV XDG_CACHE_HOME=/root/.cache

# Cloud Run sets PORT environment variable, expose it
ENV PORT=8501
EXPOSE $PORT

# Health check
HEALTHCHECK --interval=30s --timeout=10s --start-period=40s --retries=3 \
  CMD curl --fail http://localhost:$PORT/_stcore/health || exit 1

# Run Streamlit - Cloud Run will provide PORT env var
CMD streamlit run scripts/file_qa_web.py \
    --server.port=$PORT \
    --server.address=0.0.0.0 \
    --server.headless=true
